{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YegoHome/TreyebullAI/blob/main/Testfooocus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pFp30CfQekIf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWpmoaxGFCCa",
        "outputId": "a184ee85-b2a5-4527-bbe5-c43ffcf75914"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.21.0-py3-none-any.whl (17.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.0/17.0 MB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.12.0 (from gradio)\n",
            "  Downloading gradio_client-0.12.0-py3-none-any.whl (310 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.7/310.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.1.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.3)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.3.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.28.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.12.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==0.12.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Collecting colorama<0.5.0,>=0.4.3 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting shellingham<2.0.0,>=1.3.0 (from typer[all]<1.0,>=0.9->gradio)\n",
            "  Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Collecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio)\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=dba740fb47c6ed580aae389e70734fe51d3bf25e3b539615850993f8f751ce87\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, h11, colorama, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.2.1 colorama-0.4.6 fastapi-0.110.0 ffmpy-0.3.2 gradio-4.21.0 gradio-client-0.12.0 h11-0.14.0 httpcore-1.0.4 httpx-0.27.0 orjson-3.9.15 pydub-0.25.1 python-multipart-0.0.9 ruff-0.3.2 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.36.3 tomlkit-0.12.0 uvicorn-0.28.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install gradio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTXPoT_nHtPB",
        "outputId": "98a13cb1-4d0b-49c8-d9c8-3e49bce966a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting diffusers\n",
            "  Downloading diffusers-0.26.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers) (7.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.2 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.20.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from diffusers) (1.25.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from diffusers) (2.31.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from diffusers) (0.4.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from diffusers) (9.4.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (4.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.2->diffusers) (23.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->diffusers) (2024.2.2)\n",
            "Installing collected packages: diffusers\n",
            "Successfully installed diffusers-0.26.3\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.38.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.2.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install diffusers\n",
        "!pip install transformers\n",
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "4BcCIsXpIgf3",
        "outputId": "25c2b8bf-1c8e-4321-b48f-cd3bc0d14970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://7cd2f803dc80274b1c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://7cd2f803dc80274b1c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        " import gradio as gr\n",
        "\n",
        "def greet(name):\n",
        "    return \"Hello \" + name + \"!!\"\n",
        "\n",
        "iface = gr.Interface(fn=greet, inputs=\"text\", outputs=\"text\")\n",
        "iface.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMqg90lNI_Me"
      },
      "outputs": [],
      "source": [
        "from gradio import Interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ_YmVF5KhEk",
        "outputId": "09816477-4173-47c2-ed7f-446893fcc03d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Kandaki'...\n",
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Total 4 (delta 0), reused 0 (delta 0), pack-reused 4\u001b[K\n",
            "Unpacking objects: 100% (4/4), 1.27 KiB | 648.00 KiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://huggingface.co/spaces/Njinga/Kandaki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpVN7iCxMb3W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "7afa7131-4c63-4b65-b1e4-9d5bb5751287"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'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'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "userdata.get('HFGradio')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "from email import generator\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from diffusers import StableDiffusionImg2ImgPipeline\n",
        "import gradio as gr\n",
        "import torch\n",
        "\n",
        "models = [\n",
        "  \"nitrosocke/Arcane-Diffusion\",\n",
        "  \"nitrosocke/archer-diffusion\",\n",
        "  \"nitrosocke/elden-ring-diffusion\",\n",
        "  \"nitrosocke/spider-verse-diffusion\",\n",
        "  \"nitrosocke/modern-disney-diffusion\",\n",
        "  \"hakurei/waifu-diffusion\",\n",
        "  \"lambdalabs/sd-pokemon-diffusers\",\n",
        "  \"yuk/fuyuko-waifu-diffusion\",\n",
        "  \"AstraliteHeart/pony-diffusion\",\n",
        "  \"IfanSnek/JohnDiffusion\",\n",
        "  \"nousr/robo-diffusion\",\n",
        "  \"DGSpitzer/Cyberpunk-Anime-Diffusion\"\n",
        "]\n",
        "\n",
        "prompt_prefixes = {\n",
        "  models[0]: \"arcane style \",\n",
        "  models[1]: \"archer style \",\n",
        "  models[2]: \"elden ring style \",\n",
        "  models[3]: \"spiderverse style \",\n",
        "  models[4]: \"modern disney style \",\n",
        "  models[5]: \"\",\n",
        "  models[6]: \"\",\n",
        "  models[7]: \"\",\n",
        "  models[8]: \"\",\n",
        "  models[9]: \"\",\n",
        "  models[10]: \"\",\n",
        "  models[11]: \"dgs illustration style \",\n",
        "}\n",
        "\n",
        "current_model = models[0]\n",
        "pipe = StableDiffusionPipeline.from_pretrained(current_model, torch_dtype=torch.float16)\n",
        "if torch.cuda.is_available():\n",
        "  pipe = pipe.to(\"cuda\")\n",
        "\n",
        "device = \"GPU 🔥\" if torch.cuda.is_available() else \"CPU 🥶\"\n",
        "\n",
        "def inference(model, img, strength, prompt, guidance, steps, seed):\n",
        "\n",
        "  generator = torch.Generator('cuda').manual_seed(seed) if seed != 0 else None\n",
        "\n",
        "  if img is not None:\n",
        "    return img_inference(model, prompt, img, strength, guidance, steps, generator)\n",
        "  else:\n",
        "    return text_inference(model, prompt, guidance, steps, generator)\n",
        "\n",
        "def text_inference(model, prompt, guidance, steps, generator=None):\n",
        "\n",
        "    global current_model\n",
        "    global pipe\n",
        "    if model != current_model:\n",
        "        current_model = model\n",
        "        pipe = StableDiffusionPipeline.from_pretrained(current_model, torch_dtype=torch.float16)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    prompt = prompt_prefixes[current_model] + prompt\n",
        "    image = pipe(\n",
        "      prompt,\n",
        "      num_inference_steps=int(steps),\n",
        "      guidance_scale=guidance,\n",
        "      width=512,\n",
        "      height=512,\n",
        "      generator=generator).images[0]\n",
        "    return image\n",
        "\n",
        "def img_inference(model, prompt, img, strength, guidance, steps, generator):\n",
        "\n",
        "    global current_model\n",
        "    global pipe\n",
        "    if model != current_model:\n",
        "        current_model = model\n",
        "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(current_model, torch_dtype=torch.float16)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            pipe = pipe.to(\"cuda\")\n",
        "\n",
        "    prompt = prompt_prefixes[current_model] + prompt\n",
        "    img.resize((512, 512))\n",
        "    image = pipe(\n",
        "        prompt,\n",
        "        init_image=img,\n",
        "        num_inference_steps=int(steps),\n",
        "        strength=strength,\n",
        "        guidance_scale=guidance,\n",
        "        width=512,\n",
        "        height=512,\n",
        "        generator=generator).images[0]\n",
        "    return image\n",
        "\n",
        "\n",
        "css = \"\"\"\n",
        "  <style>\n",
        "  .finetuned-diffusion-div {\n",
        "      text-align: center;\n",
        "      max-width: 700px;\n",
        "      margin: 0 auto;\n",
        "    }\n",
        "    .finetuned-diffusion-div div {\n",
        "      display: inline-flex;\n",
        "      align-items: center;\n",
        "      gap: 0.8rem;\n",
        "      font-size: 1.75rem;\n",
        "    }\n",
        "    .finetuned-diffusion-div div h1 {\n",
        "      font-weight: 900;\n",
        "      margin-bottom: 7px;\n",
        "    }\n",
        "    .finetuned-diffusion-div p {\n",
        "      margin-bottom: 10px;\n",
        "      font-size: 94%;\n",
        "    }\n",
        "    .finetuned-diffusion-div p a {\n",
        "      text-decoration: underline;\n",
        "    }\n",
        "  </style>\n",
        "\"\"\"\n",
        "with gr.Blocks(css=css) as demo:\n",
        "    gr.HTML(\n",
        "        \"\"\"\n",
        "            <div class=\"finetuned-diffusion-div\">\n",
        "              <div>\n",
        "                <h1>Finetuned Diffusion</h1>\n",
        "              </div>\n",
        "              <p>\n",
        "               Demo for multiple fine-tuned Stable Diffusion models, trained on different styles: <br>\n",
        "               <a href=\"https://huggingface.co/nitrosocke/Arcane-Diffusion\">Arcane</a>, <a href=\"https://huggingface.co/nitrosocke/archer-diffusion\">Archer</a>, <a href=\"https://huggingface.co/nitrosocke/elden-ring-diffusion\">Elden Ring</a>, <a href=\"https://huggingface.co/nitrosocke/spider-verse-diffusion\">Spiderverse</a>, <a href=\"https://huggingface.co/nitrosocke/modern-disney-diffusion\">Modern Disney</a>, <a href=\"https://huggingface.co/hakurei/waifu-diffusion\">Waifu</a>, <a href=\"https://huggingface.co/lambdalabs/sd-pokemon-diffusers\">Pokemon</a>, <a href=\"https://huggingface.co/yuk/fuyuko-waifu-diffusion\">Fuyuko Waifu</a>, <a href=\"https://huggingface.co/AstraliteHeart/pony-diffusion\">Pony</a>, <a href=\"https://huggingface.co/IfanSnek/JohnDiffusion\">John</a>, <a href=\"https://huggingface.co/nousr/robo-diffusion\">Robo</a>, <a href=\"https://huggingface.co/DGSpitzer/Cyberpunk-Anime-Diffusion\">Cyberpunk Anime</a>\n",
        "              </p>\n",
        "            </div>\n",
        "        \"\"\"\n",
        "    )\n",
        "    with gr.Row():\n",
        "\n",
        "        with gr.Column():\n",
        "\n",
        "            model = gr.Dropdown(label=\"Model\", choices=models, value=models[0])\n",
        "            prompt = gr.Textbox(label=\"Prompt\", placeholder=\"Style prefix is applied automatically\")\n",
        "            with gr.Accordion(\"Image to image (optional)\", open=False):\n",
        "              image = gr.Image(label=\"Image\", height=256, tool=\"editor\", type=\"pil\")\n",
        "              strength = gr.Slider(label=\"Strength\", minimum=0, maximum=1, step=0.01, value=0.75)\n",
        "\n",
        "            with gr.Accordion(\"Advanced options\", open=False):\n",
        "              guidance = gr.Slider(label=\"Guidance scale\", value=7.5, maximum=15)\n",
        "              steps = gr.Slider(label=\"Steps\", value=50, maximum=100, minimum=2)\n",
        "              seed = gr.Slider(0, 2147483647, label='Seed (0 = random)', value=0, step=1)\n",
        "\n",
        "            run = gr.Button(value=\"Run\")\n",
        "            gr.Markdown(f\"Running on: {device}\")\n",
        "        with gr.Column():\n",
        "            image_out = gr.Image(height=512)\n",
        "\n",
        "    prompt.submit(inference, inputs=[model, image, strength, prompt, guidance, steps, seed], outputs=image_out)\n",
        "    run.click(inference, inputs=[model, image, strength, prompt, guidance, steps, seed], outputs=image_out)\n",
        "    gr.Examples([\n",
        "        [models[0], \"jason bateman disassembling the demon core\", 7.5, 50],\n",
        "        [models[3], \"portrait of dwayne johnson\", 7.0, 75],\n",
        "        [models[4], \"portrait of a beautiful alyx vance half life\", 10, 50],\n",
        "        [models[5], \"Aloy from Horizon: Zero Dawn, half body portrait, smooth, detailed armor, beautiful face, illustration\", 7, 45],\n",
        "        [models[4], \"fantasy portrait painting, digital art\", 4, 30],\n",
        "    ], [model, prompt, guidance, steps], image_out, text_inference, cache_examples=torch.cuda.is_available())\n",
        "    gr.Markdown('''\n",
        "      Models by [@nitrosocke](https://huggingface.co/nitrosocke), [@Helixngc7293](https://twitter.com/DGSpitzer) and others. ❤️<br>\n",
        "      Space by: [![Twitter Follow](https://img.shields.io/twitter/follow/hahahahohohe?label=%40anzorq&style=social)](https://twitter.com/hahahahohohe)\n",
        "\n",
        "      ![visitors](https://visitor-badge.glitch.me/badge?page_id=anzorq.finetuned_diffusion)\n",
        "    ''')\n",
        "\n",
        "demo.queue()\n",
        "demo.launch(share = True)"
      ],
      "metadata": {
        "id": "JSxrQWyvJg8K",
        "outputId": "09f904c0-aaf0-4a59-cd2a-a5750682cb2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install matplotlib\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QikM5ldpLdF8",
        "outputId": "ce8fc010-c9d9-4911-ff23-068a68ce7ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! python app.py"
      ],
      "metadata": {
        "id": "H7qo-6AWFbLH",
        "outputId": "d709206f-b484-4420-8193-9248266857ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-03-10 16:32:09.905719: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-03-10 16:32:09.905855: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-03-10 16:32:09.925501: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-03-10 16:32:13.744417: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "unet/diffusion_pytorch_model.safetensors not found\n",
            "Cannot initialize model with low cpu memory usage because `accelerate` was not found in the environment. Defaulting to `low_cpu_mem_usage=False`. It is strongly recommended to install `accelerate` for faster and less memory-intense model loading. You can do so with: \n",
            "```\n",
            "pip install accelerate\n",
            "```\n",
            ".\n",
            "Loading pipeline components...:   0% 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading pipeline components...: 100% 7/7 [00:39<00:00,  5.67s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/diffusers/pipelines/stable_diffusion/pipeline_stable_diffusion.py:182: FutureWarning: The configuration file of this scheduler: LMSDiscreteScheduler {\n",
            "  \"_class_name\": \"LMSDiscreteScheduler\",\n",
            "  \"_diffusers_version\": \"0.26.3\",\n",
            "  \"beta_end\": 0.012,\n",
            "  \"beta_schedule\": \"scaled_linear\",\n",
            "  \"beta_start\": 0.00085,\n",
            "  \"clip_sample\": false,\n",
            "  \"num_train_timesteps\": 1000,\n",
            "  \"prediction_type\": \"epsilon\",\n",
            "  \"steps_offset\": 0,\n",
            "  \"timestep_spacing\": \"linspace\",\n",
            "  \"trained_betas\": null,\n",
            "  \"use_karras_sigmas\": false\n",
            "}\n",
            " is outdated. `steps_offset` should be set to 1 instead of 0. Please make sure to update the config accordingly as leaving `steps_offset` might led to incorrect results in future versions. If you have downloaded this checkpoint from the Hugging Face Hub, it would be very nice if you could open a Pull request for the `scheduler/scheduler_config.json` file\n",
            "  deprecate(\"steps_offset!=1\", \"1.0.0\", deprecation_message, standard_warn=False)\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/app.py\", line 147, in <module>\n",
            "    image = gr.Image(label=\"Image\", height=256, tool=\"editor\", type=\"pil\")\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/component_meta.py\", line 159, in wrapper\n",
            "    return fn(self, **kwargs)\n",
            "TypeError: Image.__init__() got an unexpected keyword argument 'tool'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git add app.py && git commit -m \"Add application file\" && git push"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZmJgZD97nZZ",
        "outputId": "f8a3939a-decf-42b2-ea5b-10b88d26bb87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m2ukEWi9MI_I",
        "outputId": "245cb78f-cafa-4c5c-91a3-720c364e6342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Need 'write' access token to create a Spaces repo.\n",
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/gradio\", line 8, in <module>\n",
            "    sys.exit(cli())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/cli.py\", line 15, in cli\n",
            "    gradio.deploy_space.deploy()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gradio/deploy_space.py\", line 141, in deploy\n",
            "    huggingface_hub.login(add_to_git_credential=False)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 113, in login\n",
            "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/huggingface_hub/_login.py\", line 189, in interpreter_login\n",
            "    token = getpass(\"Token: \")\n",
            "  File \"/usr/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
            "    passwd = _raw_input(prompt, stream, input=input)\n",
            "  File \"/usr/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
            "    line = input.readline()\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!gradio deploy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygit2==1.12.2\n",
        "%cd /content\n",
        "!git clone https://github.com/lllyasviel/fooocus.git\n",
        "%cd /content/fooocus\n",
        "!python entry_with_update.py --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdalWNUQrNrU",
        "outputId": "06af368f-0e24-4dd5-a289-ef7ef5e8bb41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pygit2==1.12.2 in /usr/local/lib/python3.10/dist-packages (1.12.2)\n",
            "Requirement already satisfied: cffi>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from pygit2==1.12.2) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.9.1->pygit2==1.12.2) (2.21)\n",
            "/content\n",
            "Cloning into 'fooocus'...\n",
            "remote: Enumerating objects: 5618, done.\u001b[K\n",
            "remote: Counting objects: 100% (19/19), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 5618 (delta 5), reused 9 (delta 3), pack-reused 5599\u001b[K\n",
            "Receiving objects: 100% (5618/5618), 32.56 MiB | 30.23 MiB/s, done.\n",
            "Resolving deltas: 100% (3205/3205), done.\n",
            "/content/fooocus\n",
            "Already up-to-date\n",
            "Update succeeded.\n",
            "[System ARGV] ['entry_with_update.py', '--share']\n",
            "Python 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "Fooocus version: 2.2.1\n",
            "Error checking version for torchsde: No package metadata was found for torchsde\n",
            "Installing requirements\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xlvaeapp.pth\" to /content/fooocus/models/vae_approx/xlvaeapp.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 8.84MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/vaeapp_sd15.pt\" to /content/fooocus/models/vae_approx/vaeapp_sd15.pth\n",
            "\n",
            "100% 209k/209k [00:00<00:00, 7.35MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/xl-to-v1_interposer-v3.1.safetensors\" to /content/fooocus/models/vae_approx/xl-to-v1_interposer-v3.1.safetensors\n",
            "\n",
            "100% 6.25M/6.25M [00:00<00:00, 73.3MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/misc/resolve/main/fooocus_expansion.bin\" to /content/fooocus/models/prompt_expansion/fooocus_expansion/pytorch_model.bin\n",
            "\n",
            "100% 335M/335M [00:02<00:00, 168MB/s]\n",
            "Downloading: \"https://huggingface.co/lllyasviel/fav_models/resolve/main/fav/juggernautXL_v8Rundiffusion.safetensors\" to /content/fooocus/models/checkpoints/juggernautXL_v8Rundiffusion.safetensors\n",
            "\n",
            "100% 6.62G/6.62G [00:56<00:00, 125MB/s]\n",
            "Downloading: \"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_offset_example-lora_1.0.safetensors\" to /content/fooocus/models/loras/sd_xl_offset_example-lora_1.0.safetensors\n",
            "\n",
            "100% 47.3M/47.3M [00:00<00:00, 171MB/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/fooocus/entry_with_update.py\", line 46, in <module>\n",
            "    from launch import *\n",
            "  File \"/content/fooocus/launch.py\", line 127, in <module>\n",
            "    from webui import *\n",
            "  File \"/content/fooocus/webui.py\", line 10, in <module>\n",
            "    import modules.async_worker as worker\n",
            "  File \"/content/fooocus/modules/async_worker.py\", line 2, in <module>\n",
            "    from modules.patch import PatchSettings, patch_settings, patch_all\n",
            "  File \"/content/fooocus/modules/patch.py\", line 5, in <module>\n",
            "    import ldm_patched.modules.model_base\n",
            "  File \"/content/fooocus/ldm_patched/modules/model_base.py\", line 2, in <module>\n",
            "    from ldm_patched.ldm.modules.diffusionmodules.openaimodel import UNetModel, Timestep\n",
            "  File \"/content/fooocus/ldm_patched/ldm/modules/diffusionmodules/openaimodel.py\", line 15, in <module>\n",
            "    from ..attention import SpatialTransformer, SpatialVideoTransformer, default\n",
            "  File \"/content/fooocus/ldm_patched/ldm/modules/attention.py\", line 9, in <module>\n",
            "    from .sub_quadratic_attention import efficient_dot_product_attention\n",
            "  File \"/content/fooocus/ldm_patched/ldm/modules/sub_quadratic_attention.py\", line 27, in <module>\n",
            "    from ldm_patched.modules import model_management\n",
            "  File \"/content/fooocus/ldm_patched/modules/model_management.py\", line 121, in <module>\n",
            "    total_vram = get_total_memory(get_torch_device()) / (1024 * 1024)\n",
            "  File \"/content/fooocus/ldm_patched/modules/model_management.py\", line 90, in get_torch_device\n",
            "    return torch.device(torch.cuda.current_device())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 769, in current_device\n",
            "    _lazy_init()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/cuda/__init__.py\", line 298, in _lazy_init\n",
            "    torch._C._cuda_init()\n",
            "RuntimeError: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5ZeBTpEoXV/MWkzbaYjmH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}